{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CryCare2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMpf0JOLthnR2rKtB5axZ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/motazsaad/infant-cry-care/blob/main/CryCare2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L99t0KYoOpke",
        "outputId": "265b075a-c77f-4e2a-94bf-1c30d6a4aedd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJyZ-VMt6JRP"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials as GC\n",
        "gc = gspread.authorize(GC.get_application_default())\n",
        "title = 'CryCareSheet'\n",
        "spreedSheet = gc.open(title)\n",
        "audioContSheet = spreedSheet.sheet1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwklM2WcVIwe"
      },
      "source": [
        "\n",
        "# reportSheet = spreedSheet.worksheet('report')\n",
        "# spreedSheet.add_worksheet(title ='report', rows = 200, cols = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WQ1VYrdOZAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab574641-12f6-4215-a758-c71c0dad8f97"
      },
      "source": [
        "!pip install ffmpeg\n",
        "!pip install git+https://github.com/jiaaro/pydub.git@master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=9cf1efe352f435ae65e1a8a189a07c685fbf71653ea3f624649e9b370633fb72\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/80/6e/caa3e16deb0267c3cbfd36862058a724144e19fdb9eb03af0f\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n",
            "Collecting git+https://github.com/jiaaro/pydub.git@master\n",
            "  Cloning https://github.com/jiaaro/pydub.git (to revision master) to /tmp/pip-req-build-tbdsr85w\n",
            "  Running command git clone -q https://github.com/jiaaro/pydub.git /tmp/pip-req-build-tbdsr85w\n",
            "Building wheels for collected packages: pydub\n",
            "  Building wheel for pydub (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydub: filename=pydub-0.25.1-py2.py3-none-any.whl size=32352 sha256=40bd17b55b90ff1bbd93a7ede6d8d26b3e310627c1401c4080595da05c3e6b27\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qk577xq6/wheels/a7/e5/a1/626333b98a5e043f69b7bdd3a989b87b8ccf9005f4b66a6aef\n",
            "Successfully built pydub\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYMeUejj7Kbh"
      },
      "source": [
        "import glob\n",
        "import subprocess\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks\n",
        "from pydub.silence import split_on_silence\n",
        "import pandas as pd\n",
        "import librosa \n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "\n",
        "mainPath = '/content/drive/MyDrive/CryCareDataset/'\n",
        "originDataPath = mainPath + 'Dataset/'\n",
        "oneSecDataPath = mainPath + 'oneSecDataset/'\n",
        "onSilencePath = mainPath + 'onSilence/'\n",
        "donateACryPath = mainPath + 'donateacry/'\n",
        "directories = ['Hungry', 'lower gas', 'burp up', 'Sleepy', 'Uncomfortable'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcUnuPMIm-fV"
      },
      "source": [
        "def filterAudioFile ():\n",
        "  for directory in os.listdir(donateACryPath):\n",
        "    for file in glob.glob(donateACryPath + directory + '/**.wav'):\n",
        "      age = file.split('-')[-2]\n",
        "      filename = file.split('/')[-1]\n",
        "      newPath = originDataPath + directory + '/' + filename\n",
        "      if(age == '04' or age == '48' or age == '26'):\n",
        "        subprocess.call(['ffmpeg', '-i', file,\n",
        "                      newPath])\n",
        "filterAudioFile()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-plqdqImd1u"
      },
      "source": [
        "def convertMp3ToWav(path, directories) :\n",
        "  for directory in directories:\n",
        "    for filename in glob.glob(path + directory + '/**.mp3'):\n",
        "        filewithoutext = filename.split('.')\n",
        "        wavfile = filewithoutext[0] + '.wav'\n",
        "        subprocess.call(['ffmpeg', '-i', filename,\n",
        "                      wavfile])\n",
        "      \n",
        "#convert all directories to wav\n",
        "convertMp3ToWav(originDataPath, directories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tQsnCtV69Rd"
      },
      "source": [
        "def makeDirectory(newPath, directories):\n",
        "  try:\n",
        "    os.mkdir(newPath)\n",
        "    for directoryName in directories:\n",
        "      os.mkdir(newPath + directoryName)\n",
        "  except:\n",
        "    print('File exists')\n",
        "\n",
        "#make a new directories in drive for oneSecDataset\n",
        "makeDirectory(oneSecDataPath, directories)\n",
        "makeDirectory(onSilencePath, directories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y564eiuayXcE"
      },
      "source": [
        "#one sec chunks\n",
        "\n",
        "#Export all of the individual chunks as wav files\n",
        "def exportChunks(path, directory, filename, chunks):\n",
        "  # for i, chunk in enumerate(myaudio[::1000]):\n",
        "  for i, chunk in enumerate(chunks):\n",
        "    filewithoutext = filename.split('/')\n",
        "    name = filewithoutext[-1].split('.')[0]\n",
        "    chunk_name = name + \"chunk{0}.wav\".format(i)\n",
        "    # if(len(chunk) > 900): \n",
        "    chunk.export(path + directory + '/' + chunk_name, format=\"wav\")\n",
        "\n",
        "def makeChunks(path, directories) :\n",
        "  for directoryName in directories:\n",
        "    for filename in glob.glob(path + directoryName + '/**.wav'):\n",
        "      myaudio = AudioSegment.from_file(filename , \"wav\") \n",
        "      chunk_length_ms = 1000 # pydub calculates in millisec\n",
        "      chunks = make_chunks(myaudio, chunk_length_ms) #Make chunks of one sec\n",
        "      exportChunks(oneSecDataPath, directoryName, filename, chunks)\n",
        "\n",
        "makeChunks(originDataPath, directories)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfl56_K1fQKz"
      },
      "source": [
        "def makeChunksOnSilence(path, directories):\n",
        "  for directoryName in directories:\n",
        "    for filename in glob.glob(path + directoryName + '/**.wav'):\n",
        "      myaudio = AudioSegment.from_file(filename , \"wav\") \n",
        "      myaudio = myaudio.set_frame_rate(11025)\n",
        "      # print(len(myaudio), filename)\n",
        "      chunks = split_on_silence(myaudio, silence_thresh=-40, min_silence_len=500)\n",
        "      exportChunks(onSilencePath, directoryName, filename, chunks)\n",
        "\n",
        "makeChunksOnSilence(originDataPath, directories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOHQKCYSzUcQ"
      },
      "source": [
        "#Store all audio files in dictionary where key: filename, value: label\n",
        "def createRawAudio(path) :\n",
        "  raw_audio = dict()\n",
        "  for directory in directories :\n",
        "    for filename in glob.glob(path + directory + '/**.wav'):\n",
        "      raw_audio[filename] = directory\n",
        "  return raw_audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Da0QfNHfzR"
      },
      "source": [
        "def audioFeatureExtraction(raw_audio, featureExtraction):\n",
        "  X = pd.DataFrame(columns = np.arange(45), dtype = 'float32').astype(np.float32)\n",
        "  for i, filename in enumerate(raw_audio):\n",
        "      if filename.endswith(\".wav\"):\n",
        "          audiofile, sr = librosa.load(filename, sr = 11025)\n",
        "          fingerprint = featureExtraction(y=audiofile, sr=sr)\n",
        "          x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
        "          x[44] = raw_audio[filename]\n",
        "          X.loc[i] = x.loc[0]\n",
        "  X = X.fillna(0)\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFPAhbqIcD_Z"
      },
      "source": [
        "#Do something with missing values.\n",
        "print(X)\n",
        "print(X.isnull().sum())\n",
        "X = X.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmMhnHyhMWf1"
      },
      "source": [
        "def trainTestSplit(X):\n",
        "  y = X[44]\n",
        "  del X[44]\n",
        "  X = X.astype(np.float32)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfKVT4xfMisd",
        "cellView": "code"
      },
      "source": [
        "def get_scores(classifier, X_train, X_test, y_train, y_test, **kwargs):\n",
        "        model = classifier(**kwargs)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_predict = model.predict(X_test)\n",
        "        return classification_report(y_test, y_predict, target_names=directories, output_dict=True)\n",
        "# randomForest =  get_scores(RandomForestClassifier, X_train, X_test, y_train, y_test)\n",
        "# SVM =  get_scores(SVC, X_train, X_test, y_train, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLKWJRrqSlm7"
      },
      "source": [
        "def exportClassificationReport(report, sheetName):\n",
        "  df = pd.DataFrame(report).transpose()\n",
        "  df[''] = directories + ['accuracy', 'macro avg', 'weighted avg']\n",
        "  try:\n",
        "    spreedSheet.add_worksheet(title =sheetName, rows = 200, cols = 100)\n",
        "  except:\n",
        "    print('file exist')\n",
        "  reportSheet = spreedSheet.worksheet(sheetName)\n",
        "  set_with_dataframe(reportSheet, df) \n",
        "  # return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGAgR4gS8ebm"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df[''] = directories\n",
        "def countDirectories(path, dataName):\n",
        "  audio_count = []\n",
        "  for directoryName in directories:\n",
        "    count = 0\n",
        "    for filename in glob.glob(path + directoryName + '/**.wav'):\n",
        "      count +=1\n",
        "    audio_count.append(count)\n",
        "    count = 0\n",
        "  df[dataName] = audio_count\n",
        "\n",
        "countDirectories(originDataPath, 'originData')\n",
        "countDirectories(onSilencePath, 'onSilence')\n",
        "countDirectories(oneSecDataPath, 'oneSec')\n",
        "#save on sheet\n",
        "set_with_dataframe(worksheet1, df) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UrkOmamPKTk"
      },
      "source": [
        "def makeModel(path, featureExtraction, classifier):\n",
        "  raw_audio = createRawAudio(path)\n",
        "  X = audioFeatureExtraction(raw_audio, featureExtraction)\n",
        "  X_train, X_test, y_train, y_test = trainTestSplit(X)\n",
        "  model = get_scores(classifier, X_train, X_test, y_train, y_test)\n",
        "  return (model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1X_vHr8YZ5Y"
      },
      "source": [
        "model = makeModel(originDataPath, librosa.feature.spectral_centroid, RandomForestClassifier)\n",
        "exportClassificationReport(model, 'originData,spectralCentroid,RandomForestClassifier')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU1F00uCXn0_"
      },
      "source": [
        "model2 = makeModel(originDataPath, librosa.feature.mfcc, SVC)\n",
        "exportClassificationReport(model2, 'originData,mfcc,SVC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNtk9vxsCk8R"
      },
      "source": [
        "model3 = makeModel(oneSecDataPath, librosa.feature.mfcc, SVC)\n",
        "exportClassificationReport(model3, 'oneSecData,mfcc,SVC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj3mDKd4nH4b"
      },
      "source": [
        "model4 = makeModel(oneSecDataPath, librosa.feature.spectral_centroid, RandomForestClassifier)\n",
        "exportClassificationReport(model4, 'oneSecData,spectralCentroid,RandomForestClassifier')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGUKnCBexVlu"
      },
      "source": [
        "model5 = makeModel(onSilencePath, librosa.feature.spectral_centroid, RandomForestClassifier)\n",
        "exportClassificationReport(model5, 'onSilence,spectralCentroid,RandomForestClassifier')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldkP7KVQ3kyX"
      },
      "source": [
        "model6 = makeModel(onSilencePath, librosa.feature.mfcc, RandomForestClassifier)\n",
        "exportClassificationReport(model6, 'onSilence,mfcc,RF')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD-BDyKG47ko"
      },
      "source": [
        "model7 = makeModel(onSilencePath, librosa.feature.mfcc, SVC)\n",
        "exportClassificationReport(model7, 'onSilence,mfcc,svc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IfALWCN-fdP"
      },
      "source": [
        "model8 = makeModel(onSilencePath, librosa.feature.spectral_centroid, RandomForestClassifier)\n",
        "exportClassificationReport(model8, 'onSilence,spectralCentroid,RandomForestClassifier')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojF8-8fFCKOr"
      },
      "source": [
        "model9 = makeModel(onSilencePath, librosa.feature.chroma_stft, RandomForestClassifier)\n",
        "exportClassificationReport(model9, 'onSilence,chroma_stft,RandomForestClassifier')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7DzZc99C9dU"
      },
      "source": [
        "model10 = makeModel(onSilencePath, librosa.feature.chroma_stft, SVC)\n",
        "exportClassificationReport(model10, 'onSilence,chroma_stft,SVC')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}